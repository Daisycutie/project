import streamlit as st
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import StandardScaler


st.sidebar.title("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏ô‡πâ‡∏≤")
page = st.sidebar.radio("Select page", ("Machine Learning", "Neural Network", 
                                        "Demo Neural Network", "Demo Machine Learning"))

def page_page1():
    st.title("**Machine Learning**")
    st.markdown('‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö Kaggle ‚û° [**Big Mart Sales Dataset**](https://www.kaggle.com/datasets/shivan118/big-mart-sales-prediction-datasets/data)', unsafe_allow_html=True)
    st.subheader("**‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö**")
    st.write("‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á BigMart ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå 1,559 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏à‡∏≤‡∏Å‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤ 10 ‡πÅ‡∏´‡πà‡∏á")
    
    st.subheader("**Features**")
    st.write("""
    - **Item_Identifier** - ‡∏£‡∏´‡∏±‡∏™‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÄ‡∏â‡∏û‡∏≤‡∏∞  
    - **Item_Weight** - ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå  
    - **Item_Fat_Content** - ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏°‡∏µ‡πÑ‡∏Ç‡∏°‡∏±‡∏ô‡∏ï‡πà‡∏≥‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà  
    - **Item_Visibility** - % ‡∏Ç‡∏≠‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏£‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤  
    - **Item_Type** - ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏Ç‡∏≠‡∏á‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå  
    - **Item_MRP** - ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Ç‡∏≤‡∏¢‡∏õ‡∏•‡∏µ‡∏Å‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î  
    - **Outlet_Identifier** - ‡∏£‡∏´‡∏±‡∏™‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞  
    - **Outlet_Establishment_Year** - ‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡∏Å‡πà‡∏≠‡∏ï‡∏±‡πâ‡∏á‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤  
    - **Outlet_Size** - ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤  
    - **Outlet_Location_Type** - ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏£‡πâ‡∏≤‡∏ô‡∏ï‡∏±‡πâ‡∏á‡∏≠‡∏¢‡∏π‡πà  
    - **Outlet_Type** - ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤ (‡∏£‡πâ‡∏≤‡∏ô‡∏Ç‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏ä‡∏≥‡∏´‡∏£‡∏∑‡∏≠‡∏ã‡∏π‡πÄ‡∏õ‡∏≠‡∏£‡πå‡∏°‡∏≤‡∏£‡πå‡πÄ‡∏Å‡πá‡∏ï)  
    """)
    

    
    st.subheader("**‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå csv**")
    df = pd.read_csv("https://raw.githubusercontent.com/Daisycutie/project/refs/heads/main/projrct-intel/train%20(1).csv")
 
    st.dataframe(df)

    st.header("‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤")
    
    #‡∏´‡∏≤null
    code = """ 
    df.isnull().sum()
    """
    st.code(code, language="python")
    
    st.write("""
        ‡∏î‡∏π‡∏ß‡πà‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞ column ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ônull‡πÑ‡∏´‡∏°‡πÅ‡∏•‡πâ‡∏ß‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Å‡∏µ‡πà‡∏≠‡∏±‡∏ô
    """)
    #‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ
    code = """
    df['Item_Weight'] = df['Item_Weight'].fillna(df['Item_Weight'].mean())
    df['Outlet_Size'] = df['Outlet_Size'].fillna(df['Outlet_Size'].mode()[0])
    """
    st.code(code, language="python")
    st.write("""
        ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Item_Weight ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡πà‡∏≤ Mean \n
        ‡πÅ‡∏•‡∏∞ Outlet_Size ‡∏à‡∏∞‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏î‡πâ‡∏ß‡∏¢ Mode
    """)
    #‡πÅ‡∏ö‡πà‡∏átrain
    code = """
    X = df.drop(['Item_Outlet_Sales'], axis=1)  # Features
    y = df['Item_Outlet_Sales'] 
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42) 
    """
    st.code(code, language="python")
    st.write("""
        ‡πÄ‡∏£‡∏≤‡πÄ‡∏≠‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏°‡∏≤‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Item_Outlet_Sales‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ôX ‡πÅ‡∏•‡∏∞ ‡πÄ‡∏£‡∏≤‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÉ‡∏´‡πâ y ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå ‡πÄ‡∏£‡∏≤‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÉ‡∏´‡πâ y ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå ‡∏Ñ‡∏∑‡∏≠ Item_Outlet_Sales 
        ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏Å‡πá‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ split ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô train 80% ‡∏Å‡∏±‡∏ö test 20%  ‡πÇ‡∏î‡∏¢‡πÉ‡∏´‡πâ random state = 42
    """)
    
    #standartscaler
    code = """
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)
    """
    st.code(code, language="python")
    st.write("""
        ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ (mean) ‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏ö‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏ö‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô (standard deviation)
    """)
    
    #train svr
    code = """
    # ‡πÇ‡∏°‡πÄ‡∏î‡∏• SVR (Support Vector Regression)
    svr_model = SVR(kernel='rbf')  # ‡πÉ‡∏ä‡πâ kernel ‡πÅ‡∏ö‡∏ö Radial Basis Function
    svr_model.fit(X_train_scaled, y_train)
    svr_val_pred = svr_model.predict(X_val_scaled)
    svr_mae = mean_absolute_error(y_val, svr_val_pred)
    print(f"SVR MAE: {svr_mae:.2f}")
    """
    st.code(code, language="python")
    st.write("""
        ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ä‡πâ Support Vector Regression ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏Ç‡∏≠‡∏á SVM ‡πÉ‡∏ä‡πâ RBF Kernel ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
        ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß ‡∏ô‡∏≥‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Mean Absolute Error (MAE) ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡πà‡∏≤‡∏à‡∏£‡∏¥‡∏á‡∏°‡∏≤‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÅ‡∏Ñ‡πà‡πÑ‡∏´‡∏ô
        ‡∏¢‡∏¥‡πà‡∏á‡∏Ñ‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏ï‡πà‡∏≥ ‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
    """)
    
    #train random forest
    code = """
    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
    rf_model.fit(X_train, y_train) 
    rf_val_pred = rf_model.predict(X_val)
    rf_mae = mean_absolute_error(y_val, rf_val_pred)
    print(f"Random Forest MAE: {rf_mae:.2f}")
    """
    st.code(code, language="python")
    st.write("""
       ‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• Random Forest Regressor ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ ‡∏´‡∏•‡∏≤‡∏¢‡πÜ Decision Tree ‡∏°‡∏≤‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤ ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Å‡∏≤‡∏£‡∏™‡∏∏‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
       ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ Mean Absolute Error (MAE) 
    """)
    
    
    

   

def page_page2():
    st.title("**Neural Network**")
    st.write("‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡∏™‡∏π‡πà‡∏´‡∏ô‡πâ‡∏≤ Neural Network")
    st.subheader("‡∏Å‡∏£‡∏≤‡∏ü‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á")

def page_page3():
    st.title("**Demo Neural Network**")
   


def page_page4():
    st.title("**Demo Machine Learning**")
    # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    df = pd.read_csv("https://raw.githubusercontent.com/Daisycutie/project/refs/heads/main/projrct-intel/train%20(1).csv")

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    if df.empty:
        st.error("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ")
        return
    
    # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡πà‡∏≤ Missing Values
    df['Item_Weight'] = df['Item_Weight'].fillna(df['Item_Weight'].mean())
    df['Outlet_Size'] = df['Outlet_Size'].fillna(df['Outlet_Size'].mode()[0])
    df = pd.get_dummies(df, drop_first=True)

    # Features ‡πÅ‡∏•‡∏∞ Target Variable
    if 'Item_Outlet_Sales' not in df.columns:
        st.error("‚ùå ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'Item_Outlet_Sales' ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•!")
        return

    X = df.drop(['Item_Outlet_Sales'], axis=1)
    y = df['Item_Outlet_Sales']

    # Train-test split
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

    # Standardization
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)

    # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• SVR ‡πÅ‡∏•‡∏∞ Random Forest
    svr_model = SVR(kernel='rbf')
    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)

    # ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•
    svr_model.fit(X_train_scaled, y_train)
    rf_model.fit(X_train, y_train)

    # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤
    svr_pred = svr_model.predict(X_val_scaled)
    rf_pred = rf_model.predict(X_val)

    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤ MAE
    svr_mae = mean_absolute_error(y_val, svr_pred)
    rf_mae = mean_absolute_error(y_val, rf_pred)

    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
    st.write(f"üìä **SVR MAE:** {svr_mae:.2f}")
    st.write(f"üå≥ **Random Forest MAE:** {rf_mae:.2f}")

# ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
if page == "Machine Learning":
    page_page1()
elif page == "Neural Network":
    page_page2()
elif page == "Demo Neural Network":
    page_page3()
elif page == "Demo Machine Learning":
    page_page4()
